#![cfg_attr(test, allow(clippy::unwrap_used))]

use anyhow::{Context, Result, bail};
use backoff::ExponentialBackoffBuilder;
use bin_shared::{http_health_check, signals};
use clap::Parser;
use firezone_relay::sockets::Sockets;
use firezone_relay::{
    AddressFamily, AllocationPort, ChannelData, ClientSocket, Command, IpStack, PeerSocket, Server,
    Sleep, VERSION, control_endpoint, ebpf, sockets,
};
use futures::{FutureExt, future};
use logging::{FilterReloadHandle, err_with_src, sentry_layer};
use phoenix_channel::{Event, LoginUrl, NoParams, PhoenixChannel, get_user_agent};
use rand::rngs::StdRng;
use rand::{Rng, SeedableRng};
use secrecy::{ExposeSecret, SecretString};
use std::borrow::Cow;
use std::net::{Ipv4Addr, Ipv6Addr, SocketAddr};
use std::pin::Pin;
use std::sync::{Arc, Mutex};
use std::task::{Poll, ready};
use std::time::{Duration, Instant};
use stun_codec::rfc5766::attributes::ChannelNumber;
use telemetry::{RELAY_DSN, Telemetry};
use tokio::sync::mpsc;
use tracing::Subscriber;
use tracing_core::Dispatch;
use tracing_stackdriver::CloudTraceConfiguration;
use tracing_subscriber::{Layer, layer::SubscriberExt, util::SubscriberInitExt};
use url::Url;

const STATS_LOG_INTERVAL: Duration = Duration::from_secs(10);

const MAX_PARTITION_TIME: Duration = Duration::from_secs(60 * 60 * 24); // 24 hours

#[derive(Parser, Debug)]
struct Args {
    /// The public (i.e. internet-reachable) IPv4 address of the relay server.
    #[arg(long, env)]
    public_ip4_addr: Option<Ipv4Addr>,
    /// The public (i.e. internet-reachable) IPv6 address of the relay server.
    #[arg(long, env)]
    public_ip6_addr: Option<Ipv6Addr>,
    /// The port to listen on for STUN messages.
    #[arg(long, env, hide = true, default_value = "3478")]
    listen_port: u16,
    // See https://www.rfc-editor.org/rfc/rfc8656.html#name-allocations
    /// The lowest port used for TURN allocations.
    #[arg(long, env, hide = true, default_value = "49152")]
    lowest_port: u16,
    /// The highest port used for TURN allocations.
    #[arg(long, env, hide = true, default_value = "65535")]
    highest_port: u16,
    #[arg(long, env = "FIREZONE_API_URL")]
    api_url: Url,
    /// Token generated by the portal to authorize websocket connection.
    #[arg(env = "FIREZONE_TOKEN")]
    token: SecretString,
    /// Used as the human name for this Relay to display in the portal. If not provided,
    /// the system hostname is used by default.
    #[arg(env = "FIREZONE_NAME")]
    name: Option<String>,
    /// A seed to use for all randomness operations.
    #[arg(long, env, hide = true)]
    rng_seed: Option<u64>,

    /// How to format the logs.
    #[arg(long, env, default_value = "human", hide = true)]
    log_format: LogFormat,

    /// Which OTLP collector we should connect to.
    ///
    /// If set, we will report traces and metrics to this collector via gRPC.
    #[arg(long, env, hide = true)]
    otlp_grpc_endpoint: Option<String>,

    /// The Google Project ID to embed in spans.
    ///
    /// Set this if you are running on Google Cloud but using the OTLP trace collector.
    /// OTLP is vendor-agnostic but for spans to be correctly recognised by Google Cloud, they need the project ID to be set.
    #[arg(long, env, hide = true)]
    google_cloud_project_id: Option<String>,

    /// Enable offloading of TURN traffic to an eBPF program.
    ///
    /// Requires the name of the network interface the XDP program should be loaded onto.
    #[arg(long, env, hide = true)]
    ebpf_offloading: Option<String>,

    /// eBPF attachment mode: "generic" for SKB_MODE or "driver" for DRV_MODE.
    ///
    /// Only relevant when ebpf_offloading is enabled.
    #[arg(long, env, hide = true, default_value = "driver")]
    ebpf_attach_mode: ebpf::AttachMode,

    /// IPv4 address of the interface where eBPF is attached.
    /// Required when ebpf_offloading is set.
    #[arg(long, env)]
    ebpf_int4_addr: Option<Ipv4Addr>,

    /// IPv6 address of the interface where eBPF is attached.
    /// Required when ebpf_offloading is set.
    #[arg(long, env)]
    ebpf_int6_addr: Option<Ipv6Addr>,

    #[command(flatten)]
    health_check: http_health_check::HealthCheckArgs,

    /// The address of the local interface where we should serve our control endpoint.
    #[arg(long, env, hide = true, default_value = "127.0.0.1:9999")]
    control_endpoint: SocketAddr,

    /// Enable sentry.io crash-reporting agent.
    #[arg(long, env = "TELEMETRY", default_value_t = false)]
    telemetry: bool,
}

#[derive(clap::ValueEnum, Debug, Clone, Copy)]
enum LogFormat {
    Human,
    Json,
    GoogleCloud,
}

fn main() {
    rustls::crypto::ring::default_provider()
        .install_default()
        .expect("Calling `install_default` only once per process should always succeed");

    let args = Args::parse();

    let runtime = tokio::runtime::Builder::new_current_thread()
        .enable_all()
        .build()
        .expect("Failed to build tokio runtime");

    let mut telemetry = if args.telemetry {
        let mut telemetry = Telemetry::new();

        runtime.block_on(telemetry.start(
            args.api_url.as_str(),
            VERSION.unwrap_or("unknown"),
            RELAY_DSN,
            String::new(), // Relays don't have a Firezone ID.
        ));

        telemetry
    } else {
        Telemetry::disabled()
    };

    match runtime.block_on(try_main(args)) {
        Ok(()) => runtime.block_on(telemetry.stop()),
        Err(e) => {
            tracing::error!("{e:#}");
            runtime.block_on(telemetry.stop_on_crash());

            std::process::exit(1);
        }
    }
}

async fn try_main(args: Args) -> Result<()> {
    let filter_reload_handle = setup_tracing(&args)?;

    let ebpf = if let Some(interface) = args.ebpf_offloading.as_deref() {
        if args.ebpf_int4_addr.is_none() {
            tracing::warn!(
                "eBPF offloading enabled with but EBPF_INT4_ADDR not set. IPv6 to IPv4 relaying will not work."
            );
        }

        if args.ebpf_int6_addr.is_none() {
            tracing::warn!(
                "eBPF offloading enabled with but EBPF_INT6_ADDR not set. IPv4 to IPv6 relaying will not work."
            );
        }

        if let Some(ipv4) = args.ebpf_int4_addr
            && let Some(ipv6) = args.ebpf_int6_addr
        {
            tracing::info!(
                "eBPF offloading enabled with IPv4 address {} and IPv6 address {}",
                ipv4,
                ipv6
            );
        }

        Some(
            ebpf::Program::try_load(
                interface,
                args.ebpf_attach_mode,
                args.ebpf_int4_addr,
                args.ebpf_int6_addr,
                args.public_ip4_addr,
                args.public_ip6_addr,
            )
            .context("Failed to load eBPF TURN router")?,
        )
    } else {
        None
    };

    let public_addr = match (args.public_ip4_addr, args.public_ip6_addr) {
        (Some(ip4), Some(ip6)) => IpStack::Dual { ip4, ip6 },
        (Some(ip4), None) => IpStack::Ip4(ip4),
        (None, Some(ip6)) => IpStack::Ip6(ip6),
        (None, None) => {
            bail!("Must listen on at least one of IPv4 or IPv6")
        }
    };

    let server = Server::new(
        public_addr,
        make_rng(args.rng_seed),
        args.listen_port,
        args.lowest_port..=args.highest_port,
    );

    let last_heartbeat_sent = Arc::new(Mutex::new(Option::<Instant>::None));

    tokio::spawn(http_health_check::serve(
        args.health_check.health_check_addr,
        make_is_healthy(last_heartbeat_sent.clone()),
    ));

    tokio::spawn(control_endpoint::serve(
        args.control_endpoint,
        filter_reload_handle,
    ));

    let login = LoginUrl::relay(
        args.api_url.clone(),
        args.name.clone(),
        args.listen_port,
        args.public_ip4_addr,
        args.public_ip6_addr,
    )?;

    let mut channel = PhoenixChannel::disconnected(
        login,
        args.token.clone(),
        get_user_agent("relay", env!("CARGO_PKG_VERSION")),
        "relay",
        JoinMessage {
            stamp_secret: server.auth_secret().expose_secret().to_string(),
        },
        || {
            ExponentialBackoffBuilder::default()
                .with_max_elapsed_time(Some(MAX_PARTITION_TIME))
                .build()
        },
        Arc::new(socket_factory::tcp),
    );
    channel.connect(NoParams);

    let mut eventloop = Eventloop::new(server, ebpf, channel, public_addr, last_heartbeat_sent)?;

    tracing::info!(target: "relay", "Listening for incoming traffic on UDP port {0}", args.listen_port);

    future::poll_fn(|cx| eventloop.poll(cx))
        .await
        .context("event loop failed")?;

    tracing::info!("Goodbye!");

    Ok(())
}

/// Sets up our tracing infrastructure.
///
/// See [`log_layer`] for details on the base log layer.
///
/// ## Integration with OTLP
///
/// If the user has specified [`TraceCollector::Otlp`], we will set up an OTLP-exporter that connects to an OTLP collector specified at `Args.otlp_grpc_endpoint`.
fn setup_tracing(args: &Args) -> Result<FilterReloadHandle> {
    use opentelemetry::{global, trace::TracerProvider as _};
    use opentelemetry_otlp::WithExportConfig;

    // Use `tracing_core` directly for the temp logger because that one does not initialize a `log` logger.
    // A `log` Logger cannot be unset once set, so we can't use that for our temp logger during the setup.
    let temp_logger_guard = tracing_core::dispatcher::set_default(
        &tracing_subscriber::registry().with(log_layer(args)).into(),
    );

    let directives = std::env::var("RUST_LOG").unwrap_or_else(|_| "info".to_string());

    let (dispatch, reload_handle) = match args.otlp_grpc_endpoint.clone() {
        None => {
            let (filter, reload_handle) = logging::try_filter(&directives)?;

            let dispatch: Dispatch = tracing_subscriber::registry()
                .with(log_layer(args).with_filter(filter))
                .with(sentry_layer())
                .into();

            (dispatch, reload_handle)
        }
        Some(endpoint) => {
            let metadata = make_otel_metadata();
            let grpc_endpoint = format!("http://{endpoint}");

            tracing::trace!(target: "relay", %grpc_endpoint, "Setting up OTLP exporter for collector");

            let exporter = opentelemetry_otlp::SpanExporter::builder()
                .with_tonic()
                .with_endpoint(grpc_endpoint.clone())
                .build()
                .context("Failed to build OTLP span exporter")?;

            let tracer_provider = opentelemetry_sdk::trace::SdkTracerProvider::builder()
                .with_resource(metadata.clone())
                .with_batch_exporter(exporter)
                .build();

            global::set_tracer_provider(tracer_provider.clone());

            tracing::trace!(target: "relay", "Successfully initialized trace provider on tokio runtime");

            let exporter = opentelemetry_otlp::MetricExporter::builder()
                .with_tonic()
                .with_endpoint(grpc_endpoint)
                .build()
                .context("Failed to build OTLP metric exporter")?;

            let meter_provider = opentelemetry_sdk::metrics::SdkMeterProvider::builder()
                .with_resource(metadata)
                .with_periodic_exporter(exporter)
                .build();

            global::set_meter_provider(meter_provider);

            tracing::trace!(target: "relay", "Successfully initialized metric provider on tokio runtime");

            let (log_filter, log_reload_handle) = logging::try_filter(&directives)?;
            let (otel_filter, otel_reload_handle) = logging::try_filter(&directives)?;

            let dispatch: Dispatch = tracing_subscriber::registry()
                .with(log_layer(args).with_filter(log_filter))
                .with(
                    tracing_opentelemetry::layer()
                        .with_tracer(tracer_provider.tracer("relay"))
                        .with_filter(otel_filter),
                )
                .with(sentry_layer())
                .into();

            (dispatch, log_reload_handle.merge(otel_reload_handle))
        }
    };

    drop(temp_logger_guard); // Drop as late as possible

    dispatch
        .try_init()
        .context("Failed to initialize tracing")?;

    Ok(reload_handle)
}

/// Constructs the base log layer.
///
/// The user has a choice between:
///
/// - human-centered formatting
/// - JSON-formatting
/// - Google Cloud optimised formatting
fn log_layer<T>(args: &Args) -> Box<dyn Layer<T> + Send + Sync>
where
    T: Subscriber + for<'a> tracing_subscriber::registry::LookupSpan<'a>,
{
    match (args.log_format, args.google_cloud_project_id.clone()) {
        (LogFormat::Human, _) => tracing_subscriber::fmt::layer()
            .with_ansi(logging::stdout_supports_ansi())
            .boxed(),
        (LogFormat::Json, _) => tracing_subscriber::fmt::layer().json().boxed(),
        (LogFormat::GoogleCloud, None) => {
            tracing::warn!(target: "relay", "Emitting logs in Google Cloud format but without the project ID set. Spans will be emitted without IDs!");

            tracing_stackdriver::layer().boxed()
        }
        (LogFormat::GoogleCloud, Some(project_id)) => tracing_stackdriver::layer()
            .with_cloud_trace(CloudTraceConfiguration { project_id })
            .boxed(),
    }
}

#[derive(Debug, serde::Deserialize)]
#[serde(rename_all = "snake_case", tag = "event", content = "payload")]
enum IngressMessages {
    Init(Init),
}

#[derive(serde::Deserialize, Debug)]
struct Init {}

#[derive(serde::Serialize, PartialEq, Debug, Clone)]
struct JoinMessage {
    stamp_secret: String,
}

fn make_rng(seed: Option<u64>) -> StdRng {
    let Some(seed) = seed else {
        return StdRng::from_entropy();
    };

    tracing::info!(target: "relay", "Seeding RNG from '{seed}'");

    StdRng::seed_from_u64(seed)
}

const MAX_UDP_SIZE: usize = 65536;

struct Eventloop<R> {
    sockets: Sockets,

    server: Server<R>,
    event_rx: mpsc::Receiver<Result<IngressMessages, phoenix_channel::Error>>,
    sleep: Sleep,

    ebpf: Option<ebpf::Program>,

    sigterm: signals::Terminate,

    stats_log_interval: tokio::time::Interval,
    last_num_bytes_relayed: u64,

    buffer: [u8; MAX_UDP_SIZE],
}

impl<R> Eventloop<R>
where
    R: Rng,
{
    fn new(
        server: Server<R>,
        ebpf: Option<ebpf::Program>,
        portal: PhoenixChannel<JoinMessage, (), IngressMessages, NoParams>,
        public_address: IpStack,
        last_heartbeat_sent: Arc<Mutex<Option<Instant>>>,
    ) -> Result<Self> {
        let mut sockets = Sockets::new();

        if public_address.as_v4().is_some() {
            sockets
                .bind(server.listen_port(), AddressFamily::V4)
                .with_context(|| {
                    format!(
                        "Failed to bind to port {0} on IPv4 interfaces",
                        server.listen_port()
                    )
                })?;
        }
        if public_address.as_v6().is_some() {
            sockets
                .bind(server.listen_port(), AddressFamily::V6)
                .with_context(|| {
                    format!(
                        "Failed to bind to port {0} on IPv6 interfaces",
                        server.listen_port()
                    )
                })?;
        }

        let (event_tx, event_rx) = mpsc::channel(128);
        tokio::spawn(phoenix_channel_event_loop(
            portal,
            event_tx,
            last_heartbeat_sent,
        ));

        Ok(Self {
            server,
            event_rx,
            sleep: Sleep::default(),
            stats_log_interval: tokio::time::interval(STATS_LOG_INTERVAL),
            last_num_bytes_relayed: 0,
            sockets,
            ebpf,
            buffer: [0u8; MAX_UDP_SIZE],
            sigterm: signals::Terminate::new()?,
        })
    }

    fn poll(&mut self, cx: &mut std::task::Context<'_>) -> Poll<Result<()>> {
        loop {
            let mut ready = false;

            ready!(self.sockets.flush(cx))?;

            // Priority 1: Execute the pending commands of the server.
            if let Some(next_command) = self.server.next_command() {
                match next_command {
                    Command::SendMessage { payload, recipient } => {
                        if let Err(e) = self.sockets.try_send(
                            self.server.listen_port(),
                            recipient.into_socket(),
                            Cow::Owned(payload),
                        ) {
                            tracing::warn!(target: "relay", %recipient, "Failed to send message: {}", err_with_src(&e));
                        }
                    }
                    Command::CreateAllocation { port, family } => {
                        self.sockets.bind(port.value(), family).with_context(|| {
                            format!(
                                "Failed to bind to port {} on {family} interfaces",
                                port.value()
                            )
                        })?;

                        tracing::info!(target: "relay", %port, %family, "Created allocation");
                    }
                    Command::FreeAllocation { port, family } => {
                        self.sockets.unbind(port.value(), family).with_context(|| {
                            format!(
                                "Failed to unbind to port {} on {family} interfaces",
                                port.value()
                            )
                        })?;

                        tracing::info!(target: "relay", %port, %family, "Freeing allocation");
                    }
                    Command::CreateChannelBinding {
                        client,
                        channel_number,
                        peer,
                        allocation_port,
                    } => {
                        if let Err(e) = self.create_channel_binding_in_ebpf_map(
                            client,
                            channel_number,
                            peer,
                            allocation_port,
                        ) {
                            tracing::debug!(target: "relay", %client, "Failed to create channel binding in eBPF map: {e:#}");
                        }
                    }
                    Command::DeleteChannelBinding {
                        client,
                        channel_number,
                        peer,
                        allocation_port,
                    } => {
                        if let Err(e) = self.delete_channel_binding_in_ebpf_map(
                            client,
                            channel_number,
                            peer,
                            allocation_port,
                        ) {
                            tracing::debug!(target: "relay", %client, "Failed to delete channel binding in eBPF map: {e:#}");
                        }
                    }
                }

                ready = true;
            }

            // Priority 2: Read from our sockets.
            //
            // We read the packet with an offset of 4 bytes so we can encode the channel-data header into that without re-allocating.
            // This only matters for relaying from an allocation to a client because the data coming in on an allocation is "raw" (i.e. unwrapped) application data.
            // To allow clients to correctly associate this data, we need to wrap it in a channel-data message as depicted below.
            //
            // For traffic coming from clients that needs to be forwarded to peers, this doesn't matter because we already a channel data message and only need to forward its payload.
            //
            // However, we don't know which socket we will be reading from when we call `poll_recv_from`, which is why we always offset the read-buffer by 4 bytes like this:
            //
            //  01│23│456789....
            // ┌──┼──┼──────────────────────────┐
            // │CN│LN│PAYLOAD...                │
            // └──┴──┴──────────────────────────┘
            //       ▲
            //       │
            //       Start of read-buffer.
            //
            //  CN: Channel number
            //  LN: Length
            let (header, payload) = self.buffer.split_at_mut(4);

            match self.sockets.poll_recv_from(payload, cx) {
                Poll::Ready(Ok(sockets::Received {
                    port, // Packets coming in on the TURN port are from clients.
                    from,
                    packet,
                })) if port == self.server.listen_port() => {
                    if let Some((port, peer)) = self.server.handle_client_input(
                        packet,
                        ClientSocket::new(from),
                        Instant::now(),
                    ) {
                        // Re-parse as `ChannelData` if we should relay it.
                        let payload = ChannelData::parse(packet)
                            .expect("valid ChannelData if we should relay it")
                            .data(); // When relaying data from a client to peer, we need to forward only the channel-data's payload.

                        if let Err(e) = self.sockets.try_send(
                            port.value(),
                            peer.into_socket(),
                            Cow::Borrowed(payload),
                        ) {
                            tracing::warn!(target: "relay", %peer, "Failed to relay data to peer: {}", err_with_src(&e));
                        }
                    };

                    ready = true;
                }
                Poll::Ready(Ok(sockets::Received {
                    port, // Packets coming in on any other port are from peers.
                    from,
                    packet,
                })) => {
                    if let Some((client, channel)) = self.server.handle_peer_traffic(
                        packet,
                        PeerSocket::new(from),
                        AllocationPort::new(port),
                    ) {
                        let total_length = ChannelData::encode_header_to_slice(
                            channel,
                            packet.len() as u16,
                            header,
                        );

                        if let Err(e) = self.sockets.try_send(
                            self.server.listen_port(), // Packets coming in from peers always go out on the TURN port
                            client.into_socket(),
                            Cow::Borrowed(&self.buffer[..total_length]),
                        ) {
                            tracing::warn!(target: "relay", %client, "Failed to relay data to client: {}", err_with_src(&e));
                        };
                    };

                    ready = true;
                }
                Poll::Ready(Err(sockets::Error::Io(e))) => {
                    tracing::warn!(target: "relay", "Error while receiving message: {}", err_with_src(&e));

                    ready = true;
                }
                Poll::Ready(Err(sockets::Error::MioTaskCrashed(e))) => return Poll::Ready(Err(e)), // Fail the event-loop. We can't operate without the `mio` worker-task.
                Poll::Pending => {}
            }

            // Priority 3: Check when we need to next be woken. This needs to happen after all state modifications.
            if let Some(timeout) = self.server.poll_timeout() {
                Pin::new(&mut self.sleep).reset(timeout);
                // Purposely no `ready = true` because we just change the state of `sleep` and we poll it below.
            }

            // Priority 4: Handle time-sensitive tasks:
            if let Poll::Ready(deadline) = self.sleep.poll_unpin(cx) {
                self.server.handle_timeout(deadline);

                ready = true;
            }

            // Priority 5: Handle portal messages
            match self.event_rx.poll_recv(cx) {
                Poll::Ready(Some(Ok(IngressMessages::Init(Init {})))) => {
                    ready = true;
                }
                Poll::Ready(Some(Err(e))) => {
                    return Poll::Ready(Err(
                        anyhow::Error::new(e).context("Portal connection failed")
                    ));
                }
                Poll::Ready(None) => {
                    return Poll::Ready(Err(anyhow::Error::msg(
                        "Portal connection task terminated",
                    )));
                }
                Poll::Pending => {}
            }

            match self.sigterm.poll_recv(cx) {
                Poll::Ready(()) => return Poll::Ready(Ok(())),
                Poll::Pending => {}
            }

            if self.stats_log_interval.poll_tick(cx).is_ready() {
                let num_allocations = self.server.num_allocations();
                let num_channels = self.server.num_active_channels();

                let bytes_relayed_since_last_tick =
                    self.server.num_relayed_bytes() - self.last_num_bytes_relayed;
                self.last_num_bytes_relayed = self.server.num_relayed_bytes();

                let avg_throughput = bytes_relayed_since_last_tick / STATS_LOG_INTERVAL.as_secs();

                tracing::info!(target: "relay", "Allocations = {num_allocations} Channels = {num_channels} Throughput = {}", fmt_human_throughput(avg_throughput as f64));

                ready = true;
            }

            if !ready {
                break Poll::Pending;
            }
        }
    }

    fn create_channel_binding_in_ebpf_map(
        &mut self,
        client: ClientSocket,
        channel_number: ChannelNumber,
        peer: PeerSocket,
        allocation_port: AllocationPort,
    ) -> Result<()> {
        let Some(ebpf) = self.ebpf.as_mut() else {
            return Ok(()); // ebPF program not loaded ...
        };

        ebpf.add_channel_binding(client, channel_number, peer, allocation_port)?;

        Ok(())
    }

    fn delete_channel_binding_in_ebpf_map(
        &mut self,
        client: ClientSocket,
        channel_number: ChannelNumber,
        peer: PeerSocket,
        allocation_port: AllocationPort,
    ) -> Result<()> {
        let Some(ebpf) = self.ebpf.as_mut() else {
            return Ok(()); // ebPF program not loaded ...
        };

        ebpf.remove_channel_binding(client, channel_number, peer, allocation_port)?;

        Ok(())
    }
}

async fn phoenix_channel_event_loop(
    mut portal: PhoenixChannel<JoinMessage, (), IngressMessages, NoParams>,
    event_tx: mpsc::Sender<Result<IngressMessages, phoenix_channel::Error>>,
    last_heartbeat_sent: Arc<Mutex<Option<Instant>>>,
) {
    loop {
        match std::future::poll_fn(|cx| portal.poll(cx)).await {
            Ok(Event::SuccessResponse { .. }) => {}
            Ok(Event::JoinedRoom { topic }) => {
                tracing::info!(target: "relay", "Successfully joined room '{topic}'");
            }
            Ok(Event::ErrorResponse { topic, req_id, res }) => {
                tracing::warn!(target: "relay", "Request with ID {req_id} on topic {topic} failed: {res:?}");
            }
            Ok(Event::HeartbeatSent) => {
                tracing::debug!(target: "relay", "Heartbeat sent to portal");
                *last_heartbeat_sent
                    .lock()
                    .unwrap_or_else(|e| e.into_inner()) = Some(Instant::now());
            }
            Ok(Event::InboundMessage { msg, .. }) => {
                if event_tx.send(Ok(msg)).await.is_err() {
                    tracing::debug!("Event channel closed: exiting phoenix-channel event-loop");
                    break;
                }
            }
            Ok(Event::Closed) => break,
            Ok(Event::Hiccup {
                backoff,
                max_elapsed_time,
                error,
            }) => tracing::warn!(?backoff, ?max_elapsed_time, "{error:#}"),
            Err(e) => {
                let _ = event_tx.send(Err(e)).await; // We don't care about the result because we are exiting anyway.

                break;
            }
        }
    }
}

fn fmt_human_throughput(mut throughput: f64) -> String {
    let units = ["B/s", "kB/s", "MB/s", "GB/s", "TB/s"];

    for unit in units {
        if throughput < 1000.0 {
            return format!("{throughput:.2} {unit}");
        }

        throughput /= 1000.0;
    }

    format!("{throughput:.2} TB/s")
}

/// Factory fn for [`is_healthy`].
fn make_is_healthy(
    last_heartbeat_sent: Arc<Mutex<Option<Instant>>>,
) -> impl Fn() -> bool + Clone + Send + Sync + 'static {
    move || is_healthy(Instant::now(), last_heartbeat_sent.clone())
}

fn is_healthy(now: Instant, last_heartbeat_sent: Arc<Mutex<Option<Instant>>>) -> bool {
    let guard = last_heartbeat_sent
        .lock()
        .unwrap_or_else(|e| e.into_inner());

    let Some(last_hearbeat_sent) = *guard else {
        return true; // If we are not connected to the portal, we are always healthy.
    };

    now.duration_since(last_hearbeat_sent) < MAX_PARTITION_TIME
}

fn make_otel_metadata() -> opentelemetry_sdk::Resource {
    use opentelemetry::{Key, KeyValue};
    use opentelemetry_sdk::Resource;
    use opentelemetry_sdk::resource::{EnvResourceDetector, TelemetryResourceDetector};

    const SERVICE_NAMESPACE: Key = Key::from_static_str("service.namespace");

    Resource::builder_empty()
        .with_service_name("relay")
        .with_attribute(KeyValue::new(SERVICE_NAMESPACE, "firezone"))
        .with_detector(Box::new(TelemetryResourceDetector))
        .with_detector(Box::new(EnvResourceDetector::new())) // Allow overriding metadata using `OTEL_RESOURCE_ATTRIBUTES` env var.
        .build()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn prints_humanfriendly_throughput() {
        assert_eq!(fmt_human_throughput(42.0), "42.00 B/s");
        assert_eq!(fmt_human_throughput(1_234.0), "1.23 kB/s");
        assert_eq!(fmt_human_throughput(955_333_999.0), "955.33 MB/s");
        assert_eq!(fmt_human_throughput(100_000_000_000.0), "100.00 GB/s");
    }

    // If we are running in standalone mode, we are always healthy.
    #[test]
    fn given_no_heartbeat_is_healthy() {
        let is_healthy = is_healthy(Instant::now(), Arc::new(Mutex::new(None)));

        assert!(is_healthy)
    }

    #[test]
    fn given_heartbeat_in_last_15_min_is_healthy() {
        let now = Instant::now() + Duration::from_hours(1);

        let is_healthy = is_healthy(
            now,
            Arc::new(Mutex::new(Some(now - Duration::from_secs(10)))),
        );

        assert!(is_healthy)
    }

    #[test]
    fn given_last_heartbeat_older_than_24_hours_is_not_healthy() {
        let now = Instant::now() + Duration::from_hours(48); // Advance to the future to avoid underflow.

        let is_healthy = is_healthy(
            now,
            Arc::new(Mutex::new(Some(now - Duration::from_hours(24)))),
        );

        assert!(!is_healthy)
    }

    // Regression tests to ensure we can parse sockets as well as domains for the otlp-grpc endpoint.
    #[test]
    fn args_can_parse_otlp_endpoint_from_socket() {
        let args = Args::try_parse_from([
            "relay",
            "--otlp-grpc-endpoint",
            "127.0.0.1:4317",
            "--api-url",
            "localhost:1234",
            "TOKEN",
        ])
        .unwrap();

        assert_eq!(args.otlp_grpc_endpoint.unwrap(), "127.0.0.1:4317");
    }

    #[test]
    fn args_can_parse_otlp_endpoint_from_domain() {
        let args = Args::try_parse_from([
            "relay",
            "--otlp-grpc-endpoint",
            "localhost:4317",
            "--api-url",
            "localhost:1234",
            "TOKEN",
        ])
        .unwrap();

        assert_eq!(args.otlp_grpc_endpoint.unwrap(), "localhost:4317");
    }
}
